# Kaggle Competition Project

# Jigsaw-Toxic-Comment-Classification

## Project Overview
The Toxic Comment Classification project is an application that uses machine learning to identify toxic comments. The application uses a dataset of comments from social media platforms, such as Twitter, to train a model that can detect toxic comments. The goal of the project is to develop a model that can accurately classify toxic comments and help moderators filter out comments that violate community guidelines.

## Website

## Dataset
The dataset used in this project is the Toxic Comment Classification Challenge from Kaggle. The dataset contains approximately 159,000 comments from Wikipedia talk pages that have been labeled by human annotators as toxic or non-toxic. The dataset includes six different types of toxicity: toxic, severe toxic, obscene, threat, insult, and identity hate. The dataset is split into a training set and a testing set, with approximately 80% of the comments in the training set and 20% in the testing set.

## Model Information

## Contributions

## License
MIT License
